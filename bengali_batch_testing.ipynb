{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bengali batch testing",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dmefcYSwC79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeEoRk1_4ZZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TQQxYSY5iWK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_lines_neu = []\n",
        "categories_neu = {}\n",
        "categories_neg = {}\n",
        "categories_pos = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQBzNQpR5kNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "with open('BN_NEU.txt','r') as f:\n",
        "  lines_neu = f.readlines()\n",
        "  lines_neu = lines_neu[65:]\n",
        "  for line in lines_neu:\n",
        "      new_lines = line.split()\n",
        "      categories_neu[new_lines[1]] = [0,0,1]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2QxwC-u550D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('BN_NEG.txt','r') as f:\n",
        "  lines_neg = f.readlines()\n",
        "  lines_neg = lines_neg[65:]\n",
        "  for line in lines_neg:\n",
        "      new_lines = line.split()\n",
        "      categories_neg[new_lines[1]] = [0,1,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyUXjd165_3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('BN_POS.txt','r') as f:\n",
        "  lines_pos = f.readlines()\n",
        "  lines_pos = lines_pos[65:]\n",
        "  for line in lines_pos:\n",
        "      new_lines = line.split()\n",
        "      categories_pos[new_lines[1]] = [1,0,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Whe6ocGu6EAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Here we merge the categories and convert them into a dictionary\n",
        "merge = [categories_neg,categories_neu,categories_pos]\n",
        "new_categories = {}\n",
        "for x in merge:\n",
        "  new_categories.update(x)\n",
        "keys = list(new_categories.keys())\n",
        "random.shuffle(keys)\n",
        "new_categories1 = [(key, new_categories[key]) for key in keys]  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92i2xQp_6VDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Here we check the length of the categories dictionary\n",
        "new_categories1 = dict(new_categories1)\n",
        "print(len(new_categories1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AZ6oVxED8Ku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating a new list to store the categories\n",
        "categories = []\n",
        "keys = list(new_categories1.keys())\n",
        "for i,k in new_categories1.items():\n",
        "  categories.append(k)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgLBfiB7XvtF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Printing the length of categories list\n",
        "print(len(categories))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVR2ahmxD_j0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Storing all the letters in a set so that there is no redundancy\n",
        "all_letters = set('কখগঘঙচছজঝঞটঠডঢণতথদধনপফবভমযরলশষসহড়ঢ়য়ৎ◌্◌ঁ◌ং◌ঃ◌ি◌া◌ী◌ু◌ূ◌ৃ◌ৄ◌ৢ◌ৣ ে◌ ৈ◌ ে◌া ে◌ৗaআiঈuঊঋeঐoঔ')\n",
        "all_letters = list(all_letters)\n",
        "print(len(all_letters))\n",
        "n_letters = 65"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHDmBTqdEJfR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "def letterToIndex(letter):\n",
        "  \"\"\"This function maps letters to integers\"\"\"\n",
        "  try:\n",
        "    for i,k in enumerate(all_letters):\n",
        "      if letter == k:\n",
        "        return i\n",
        "  except:\n",
        "    print('please enter a valid character')\n",
        "\n",
        "def letterToTensor(letter):\n",
        "    \"\"\"Here we convert a letter to a tensor\"\"\"\n",
        "    tensor = torch.zeros(1, n_letters)\n",
        "    tensor[0][letterToIndex(letter)] = 1\n",
        "\n",
        "    return tensor\n",
        "\n",
        "def lineToTensor(line):\n",
        "    \"\"\"Here we convert lines to tensors\"\"\"\n",
        "    tensor = torch.zeros(len(line), 1, n_letters)\n",
        "    for li, letter in enumerate(line):\n",
        "        if letterToIndex(letter) != -1:\n",
        "          tensor[li][0][letterToIndex(letter)] = 1\n",
        "        \n",
        "    return tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UbhxA3IYSNK",
        "colab_type": "text"
      },
      "source": [
        "#Training with Conv1D,LSTM and Linear transformation layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYO7VRw-R4H7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Conv_LSTM(nn.Module):\n",
        "    \"\"\"Here we build a custom class with Conv1D,LSTM and Linear transformation layers\"\"\"\n",
        "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
        "        \n",
        "        super(Conv_LSTM, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.c1 = nn.Conv1d(input_size, hidden_size, 1)\n",
        "        self.c2 = nn.Conv1d(hidden_size, hidden_size, 1)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, n_layers, dropout=0.01)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, inputs, hidden):\n",
        "\n",
        "        batch_size = inputs.size(1)\n",
        "        inputs = inputs.transpose(0, 1).transpose(1, 2)\n",
        "        c = self.c1(inputs)\n",
        "        p = self.c2(c)\n",
        "        p = p.transpose(1, 2).transpose(0, 1)        \n",
        "        p = torch.tanh(p)\n",
        "        output, hidden = self.lstm(p, hidden)\n",
        "        conv_seq_len = output.size(0)\n",
        "        output = output.view(conv_seq_len * batch_size, self.hidden_size)\n",
        "        output = torch.tanh(self.out(output))\n",
        "        output = output.view(conv_seq_len, -1, self.output_size)\n",
        "\n",
        "        return output, hidden\n",
        "#Declaration of Hyperparameters\n",
        "input_size = n_letters\n",
        "hidden_size = 50\n",
        "output_size = 3\n",
        "batch_size = 1\n",
        "n_layers = 2\n",
        "seq_len = 15\n",
        "#Declaraing object of the model Conv_LSTM\n",
        "rnn2 = Conv_LSTM(input_size, hidden_size, output_size, n_layers=n_layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LRgLFc6dt3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def categoryFromOutput(output):\n",
        "    \"\"\"This function converts the output into one-hot vector\"\"\"\n",
        "    top_n, top_i = output.topk(1)\n",
        "    category_i = top_i[0].item()\n",
        "    l = [0,0,0]\n",
        "    l[category_i] = l[category_i]+1\n",
        "    return l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBbjnun4mfZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(params = rnn2.parameters(),lr = 0.5) \n",
        "\n",
        "def train(category_tensors, line_tensors):\n",
        "  \"\"\"This function is used for training the model\"\"\"\n",
        "  final_loss = 0\n",
        "  correct_count = 0\n",
        "  for i in range(0,100):\n",
        "    line_tensor = line_tensors[i]\n",
        "    category = category_tensors[i] \n",
        "    category_tensor = torch.tensor(category, dtype=torch.float)\n",
        "    hidden = None\n",
        "    \n",
        "    for j in range(line_tensor.size()[0]):\n",
        "        output,hidden = rnn2(line_tensor[j].view(1,-1).unsqueeze(1),hidden)\n",
        "    guess_i = categoryFromOutput(output)\n",
        "    \n",
        "    if guess_i == category:\n",
        "      correct =  '✓'\n",
        "      correct_count = correct_count + 1\n",
        "    else:\n",
        "      correct =  '✗ (%s)' % category \n",
        "    loss = criterion(output.view(1,-1), category_tensor.view(1,3))\n",
        "    final_loss = final_loss + loss\n",
        "\n",
        "  final_loss = final_loss/100\n",
        "\n",
        "  final_loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  return final_loss,correct_count  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqkhvomAoWm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_iters = 3900\n",
        "cat_tensors = []\n",
        "line_tensors = []\n",
        "all_losses = []\n",
        "epochs = 5\n",
        "#We train the model in batches and print out the accuracy \n",
        "for epoch in range(epochs):\n",
        "\n",
        "  batch_num = 0\n",
        "  correct_sum = 0\n",
        "  final_loss = 0\n",
        "  rnn2.zero_grad()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  for iter in range(0,n_iters):\n",
        "    \n",
        "    while True:\n",
        "      \n",
        "      category = new_categories1[keys[iter]]\n",
        "      cat_tensors.append(category)\n",
        "      line_tensor = lineToTensor(keys[iter])\n",
        "      line_tensors.append(line_tensor)\n",
        "      if iter % 100 != 0 or iter == 0:\n",
        "        break\n",
        "\n",
        "      else:\n",
        "        batch_num = batch_num + 1\n",
        "        final_loss,correct = train(cat_tensors,line_tensors)\n",
        "        correct_sum = correct_sum + correct\n",
        "        cat_tensors.clear()\n",
        "        line_tensors.clear()\n",
        "        \n",
        "        if iter != 0:\n",
        "          print('%d %s %.4f  %s %s' % (batch_num, iter , final_loss, correct_sum,epoch))\n",
        "          break\n",
        "\n",
        "  print( 'accuracy is %.6f%%' % (correct_sum/3900 * 100)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDHiT0XsTgN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate2(line_tensor):\n",
        "    \"\"\"This function is used to evaluate the model\"\"\"\n",
        "    hidden = None\n",
        "    for i in range(line_tensor.size()[0]):\n",
        "      output,hidden = rnn2(line_tensor[i].view(1,-1).unsqueeze(1),hidden)\n",
        "        \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82asvoScTgQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_corr2 = 0\n",
        "n_iters = 3900\n",
        "#Here we evaluate the testing data\n",
        "for i in range(n_iters+1,4902):\n",
        "  \n",
        "  category = new_categories1[keys[i]]\n",
        "  category_tensor = torch.tensor(category, dtype=torch.float)\n",
        "  line_tensor = lineToTensor(keys[i])\n",
        "  output = evaluate2(line_tensor)\n",
        "  guess_new = categoryFromOutput(output)  \n",
        "  if guess_new == category:\n",
        "    correct =  '✓'\n",
        "    num_corr2 = num_corr2 + 1\n",
        "  else:\n",
        "    correct =  '✗ (%s)' % category \n",
        "  print('%d %d%%  %s' % (i, i / n_iters * 100,correct))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BO_MqaSBTgTw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Here we print the accuracy\n",
        "print(num_corr2/10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORq4uHQIcVVv",
        "colab_type": "text"
      },
      "source": [
        "#Training with Conv1D,GRU and Linear transformation layers "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F42peSkZTgko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Conv_GRU(nn.Module):\n",
        "    \"\"\"Here we build a custom class with Conv1D,GRU and Linear transformation layers\"\"\"\n",
        "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
        "        super(Conv_GRU, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.c1 = nn.Conv1d(input_size, hidden_size, 1)\n",
        "        self.c2 = nn.Conv1d(hidden_size, hidden_size, 1)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=0.01)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, inputs, hidden):\n",
        "\n",
        "        batch_size = inputs.size(1)\n",
        "        inputs = inputs.transpose(0, 1).transpose(1, 2)\n",
        "        c = self.c1(inputs)\n",
        "        p = self.c2(c)\n",
        "        p = p.transpose(1, 2).transpose(0, 1)\n",
        "        p = torch.tanh(p)\n",
        "        output, hidden = self.gru(p, hidden)\n",
        "        conv_seq_len = output.size(0)\n",
        "        output = output.view(conv_seq_len * batch_size, self.hidden_size) \n",
        "        output = torch.tanh(self.out(output))\n",
        "        output = output.view(conv_seq_len, -1, self.output_size)\n",
        "\n",
        "        return output, hidden\n",
        "\n",
        "#Declaration of Hyperparameters\n",
        "input_size = n_letters\n",
        "hidden_size = 50\n",
        "output_size = 3\n",
        "batch_size = 1\n",
        "n_layers = 2\n",
        "seq_len = 15\n",
        "#Declaraing object of the model Conv_GRU\n",
        "rnn = Conv_GRU(input_size, hidden_size, output_size, n_layers=n_layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WeysqwnpnxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(params = rnn.parameters(),lr = 0.5)\n",
        "\n",
        "def train(category_tensors, line_tensors):\n",
        "  \"\"\"This function is used for training the model\"\"\"\n",
        "  final_loss = 0\n",
        "  correct_count = 0\n",
        "  for i in range(0,100):\n",
        "    line_tensor = line_tensors[i]\n",
        "    category = category_tensors[i] \n",
        "    category_tensor = torch.tensor(category, dtype=torch.float)\n",
        "    hidden = None\n",
        "    \n",
        "    for j in range(line_tensor.size()[0]):\n",
        "        output,hidden = rnn(line_tensor[j].view(1,-1).unsqueeze(1),hidden)\n",
        "    guess_i = categoryFromOutput(output)\n",
        "    \n",
        "    if guess_i == category:\n",
        "      correct =  '✓'\n",
        "      correct_count = correct_count + 1\n",
        "    else:\n",
        "      correct =  '✗ (%s)' % category \n",
        "    loss = criterion(output.view(1,-1), category_tensor.view(1,3))\n",
        "    final_loss = final_loss + loss\n",
        "\n",
        "  final_loss = final_loss/100\n",
        "\n",
        "  final_loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  return final_loss,correct_count  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osn0JsYxpvTp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_iters = 3900\n",
        "cat_tensors = []\n",
        "line_tensors = []\n",
        "all_losses = []\n",
        "epochs = 5\n",
        "#we train the model in batches and print out the accuracy \n",
        "for epoch in range(epochs):\n",
        "\n",
        "  batch_num = 0\n",
        "  correct_sum = 0\n",
        "  final_loss = 0\n",
        "  rnn.zero_grad()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  for iter in range(0,n_iters):\n",
        "    \n",
        "    while True:\n",
        "      \n",
        "      category = new_categories1[keys[iter]]\n",
        "      cat_tensors.append(category)\n",
        "      line_tensor = lineToTensor(keys[iter])\n",
        "      line_tensors.append(line_tensor)\n",
        "      \n",
        "      if iter % 100 != 0 or iter == 0:\n",
        "        break\n",
        "\n",
        "      else:\n",
        "        batch_num = batch_num + 1\n",
        "        final_loss,correct = train(cat_tensors,line_tensors)\n",
        "        correct_sum = correct_sum + correct\n",
        "        cat_tensors.clear()\n",
        "        line_tensors.clear()\n",
        "\n",
        "        if iter != 0:\n",
        "          print('%d %s %.4f  %s %s' % (batch_num, iter , final_loss, correct_sum,epoch))\n",
        "          break\n",
        "\n",
        "  print( 'accuracy is %.6f%%' % (correct_sum/3900 * 100)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZqALZjddGLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(line_tensor):\n",
        "    \"\"\"This function is used to evaluate the model\"\"\"\n",
        "    hidden = None\n",
        "    for i in range(line_tensor.size()[0]):\n",
        "      output,hidden = rnn(line_tensor[i].view(1,-1).unsqueeze(1),hidden)\n",
        "        \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9wi6-3heLn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_corr = 0\n",
        "n_iters = 3900\n",
        "#Here we evaluate the testing data\n",
        "for i in range(n_iters+1,4902):\n",
        "  \n",
        "  category = new_categories1[keys[i]]\n",
        "  category_tensor = torch.tensor(category, dtype=torch.float)\n",
        "  line_tensor = lineToTensor(keys[i])\n",
        "  output = evaluate(line_tensor)\n",
        "  guess_new = categoryFromOutput(output)\n",
        "\n",
        "  if guess_new == category:\n",
        "\n",
        "    correct =  '✓'\n",
        "    num_corr = num_corr + 1\n",
        "\n",
        "  else:\n",
        "\n",
        "    correct =  '✗ (%s)' % category \n",
        "    \n",
        "  print('%d %d%% %s' % (i, i / n_iters * 100,correct)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNJBH2qgPSmU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Here we are the printing the accuracy of the testing data \n",
        "print(num_corr/10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oMqWHR3dz8-",
        "colab_type": "text"
      },
      "source": [
        "#Training with Conv1D and Linear Transformation Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIuMpODnGTpW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Convolution_Layer(nn.Module):\n",
        "    \"\"\"Here we build a custom class with Conv1D and linear transformation layers\"\"\"\n",
        "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
        "\n",
        "        super(Convolution_Layer, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.c1 = nn.Conv1d(in_channels, out_channels, kernel_size= 1)\n",
        "        self.c2 = nn.Conv1d(out_channels,out_channels, kernel_size = 1)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim = 1)\n",
        "\n",
        "    def forward(self, inputs, hidden):\n",
        "\n",
        "        batch_size = inputs.size(1)\n",
        "        c = self.c1(inputs)\n",
        "        c = self.c2(c)\n",
        "        output = c.view(-1,1)\n",
        "        output = self.softmax(self.out(output))\n",
        "\n",
        "        return output\n",
        "\n",
        "    def initHidden(self):\n",
        "\n",
        "        return torch.zeros(1, self.hidden_size)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-UmNtyfGZPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Declaration of Hyperparameters\n",
        "in_channels = n_letters\n",
        "out_channels = 1\n",
        "output_size = 3\n",
        "batch_size = 1\n",
        "n_layers = 2\n",
        "\n",
        "#Declaraing object of the model Convolution_Layer\n",
        "cnn = Convolution_Layer(in_channels, out_channels, output_size, n_layers=n_layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iT9FE70Zxr3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adadelta(params = cnn.parameters(),lr = 0.5)\n",
        "\n",
        "def train(category_tensors, line_tensors):\n",
        "  \"\"\"This function is used for training the model\"\"\"\n",
        "  final_loss = 0\n",
        "  correct_count = 0\n",
        "  for i in range(0,100):\n",
        "    line_tensor = line_tensors[i]\n",
        "    category = category_tensors[i] \n",
        "    category_tensor = torch.tensor(category, dtype=torch.float)\n",
        "    hidden = cnn.initHidden()\n",
        "    \n",
        "    for j in range(line_tensor.size()[0]):\n",
        "        output = cnn(line_tensor[j].unsqueeze(2),hidden)\n",
        "    guess_i = categoryFromOutput(output)\n",
        "    \n",
        "    if guess_i == category:\n",
        "      correct =  '✓'\n",
        "      correct_count = correct_count + 1\n",
        "    else:\n",
        "      correct =  '✗ (%s)' % category \n",
        "    loss = criterion(output, category_tensor.view(1,3))\n",
        "    final_loss = final_loss + loss\n",
        "\n",
        "  final_loss = final_loss/100\n",
        "\n",
        "  final_loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  return final_loss,correct_count "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nUZ75l9Zx0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "n_iters = 3900\n",
        "cat_tensors = []\n",
        "line_tensors = []\n",
        "all_losses = []\n",
        "epochs = 5\n",
        "#We train the model in batches and print out the accuracy \n",
        "for epoch in range(epochs):\n",
        "\n",
        "  batch_num = 0\n",
        "  correct_sum = 0\n",
        "  final_loss = 0\n",
        "  cnn.zero_grad()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  for iter in range(0,n_iters):\n",
        "    \n",
        "    while True:\n",
        "      \n",
        "      category = new_categories1[keys[iter]]\n",
        "      cat_tensors.append(category)\n",
        "      line_tensor = lineToTensor(keys[iter])\n",
        "      line_tensors.append(line_tensor)\n",
        "\n",
        "      if iter % 100 != 0 or iter == 0:\n",
        "        \n",
        "        break\n",
        "\n",
        "      else:\n",
        "\n",
        "        batch_num = batch_num + 1\n",
        "        final_loss,correct = train(cat_tensors,line_tensors)\n",
        "        correct_sum = correct_sum + correct\n",
        "        cat_tensors.clear()\n",
        "        line_tensors.clear()\n",
        "\n",
        "        if iter != 0:\n",
        "          print('%d %s %.4f  %s %s' % (batch_num, iter , final_loss, correct_sum,epoch))\n",
        "          break\n",
        "\n",
        "  print( 'accuracy is %.6f%%' % (correct_sum/3900 * 100)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1whylgZyZyAi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(line_tensor):\n",
        "    \"\"\"This function is used to evaluate the model\"\"\"\n",
        "    hidden = cnn.initHidden()\n",
        "    for i in range(line_tensor.size()[0]):\n",
        "      output = cnn(line_tensor[i].unsqueeze(2),hidden) \n",
        "             \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEQSgW_neIxt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_corr = 0\n",
        "n_iters = 3900\n",
        "#Here we evaluate the testing data\n",
        "for i in range(n_iters+1,4902):\n",
        "  \n",
        "  category = new_categories1[keys[i]]\n",
        "  category_tensor = torch.tensor(category, dtype=torch.float)\n",
        "  line_tensor = lineToTensor(keys[i])\n",
        "  output = evaluate(line_tensor)\n",
        "  guess_new = categoryFromOutput(output)  \n",
        "  if guess_new == category:\n",
        "\n",
        "    correct =  '✓'\n",
        "    num_corr = num_corr + 1\n",
        "\n",
        "  else:\n",
        "\n",
        "    correct =  '✗ (%s)' % category \n",
        "    \n",
        "  print('%d %d%% %s' % (i, i / n_iters * 100,correct)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jODvvAjbQmm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Here we are priniting the accuracy of the testing data\n",
        "print(num_corr/10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUlytCfefGRz",
        "colab_type": "text"
      },
      "source": [
        "#Training with LSTM and Linear transformation layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-nSgS58hrgc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentimentNet(nn.Module):\n",
        "    \"\"\"Here we build a custom class with LSTM and Linear transformation layers\"\"\"\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
        "\n",
        "        super(SentimentNet, self).__init__()\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True,bidirectional = True)\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "        \n",
        "    def forward(self, x, hidden,batch_size):\n",
        "\n",
        "        x = x.long()\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "        out = self.softmax(out)\n",
        "        out = out.view(batch_size, -1)\n",
        "        out = out[:,-3:]\n",
        "\n",
        "        return out, hidden\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "\n",
        "        weight = next(self.parameters()).data\n",
        "        hidden = (weight.new(self.n_layers * 2, batch_size, self.hidden_dim).zero_().to(device),\n",
        "                      weight.new(self.n_layers * 2, batch_size, self.hidden_dim).zero_().to(device))\n",
        "        \n",
        "        return hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tFbgROkhu7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Declaration of hyperparameters\n",
        "vocab_size = n_letters\n",
        "output_size = 3\n",
        "embedding_dim = n_letters\n",
        "hidden_dim = 512\n",
        "n_layers = 2\n",
        "batch_size = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y3wYOVTey_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "is_cuda = torch.cuda.is_available()\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwvDcdLAhyP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Declaration of model object\n",
        "model = SentimentNet(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "model.to(device)\n",
        "\n",
        "lr=0.5\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adadelta(model.parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz6sfXNSyeca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def categoryFromOutput(output):\n",
        "    \"\"\"This function converts the output into one-hot vector\"\"\"\n",
        "    top_n, top_i = output.topk(1)\n",
        "    category_i = top_i[0].item()\n",
        "    l = [0,0,0]\n",
        "    l[category_i] = l[category_i]+1\n",
        "    return  l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RLc1GgQhazRL",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adadelta(params = cnn.parameters(),lr = 0.5)\n",
        "def train(category_tensors, line_tensors):\n",
        "  \"\"\"This function is used for training the model\"\"\"\n",
        "  final_loss = 0\n",
        "  correct_count = 0\n",
        "  for i in range(0,100):\n",
        "    line_tensor = line_tensors[i]\n",
        "    category = category_tensors[i] \n",
        "    category_tensor = torch.tensor(category, dtype=torch.float)\n",
        "    hidden = model.init_hidden(batch_size)\n",
        "    \n",
        "    for j in range(line_tensor.size()[0]):\n",
        "        output,hidden = model(line_tensor[j].to(device),hidden,batch_size)\n",
        "    guess_i = categoryFromOutput(output)\n",
        "    \n",
        "    if guess_i == category:\n",
        "      \n",
        "      correct =  '✓'\n",
        "      correct_count = correct_count + 1\n",
        "    else:\n",
        "      correct =  '✗ (%s)' % category \n",
        "    loss = criterion(output.to(device), category_tensor.view(1,3).to(device))\n",
        "    final_loss = final_loss + loss\n",
        "\n",
        "  final_loss = final_loss/100\n",
        "\n",
        "  final_loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  return final_loss,correct_count  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "apjYTLdHazRN",
        "colab": {}
      },
      "source": [
        "n_iters = 3900\n",
        "category_list = []\n",
        "cat_tensors = []\n",
        "line_tensors = []\n",
        "all_losses = []\n",
        "epochs = 2\n",
        "#we train the model in batches and print out the accuracy \n",
        "for epoch in range(epochs):\n",
        "\n",
        "  batch_num = 0\n",
        "  correct_sum = 0\n",
        "  final_loss = 0\n",
        "  model.zero_grad()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  for iter in range(0,n_iters):\n",
        "    \n",
        "    while True:\n",
        "      \n",
        "      category = new_categories1[keys[iter]]\n",
        "      category_list.append(category)\n",
        "      cat_tensors.append(category)\n",
        "      line_tensor = lineToTensor(keys[iter])\n",
        "      line_tensors.append(line_tensor)\n",
        "      if iter % 100 != 0 or iter == 0:\n",
        "        break\n",
        "      else:\n",
        "        batch_num = batch_num + 1\n",
        "        final_loss,correct = train(cat_tensors,line_tensors)\n",
        "        correct_sum = correct_sum + correct\n",
        "        cat_tensors.clear()\n",
        "        line_tensors.clear()\n",
        "        if iter != 0:\n",
        "          print('%d %s %.4f  %s %s' % (batch_num, iter , final_loss, correct_sum,epoch))\n",
        "          break\n",
        "  print( 'accuracy is %.6f%%' % (correct_sum/3900 * 100))     \n",
        "\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IvtfC8MYazRO",
        "colab": {}
      },
      "source": [
        "def evaluate(line_tensor):\n",
        "    \"\"\"This function is used to evaluate the model\"\"\"\n",
        "    hidden = model.init_hidden(batch_size)\n",
        "    for i in range(line_tensor.size()[0]):\n",
        "      output,hidden = model(line_tensor[i].to(device),hidden,batch_size)\n",
        "        \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "glRBUE4lazRQ",
        "colab": {}
      },
      "source": [
        "num_corr = 0\n",
        "n_iters = 3900\n",
        "#Here we evaluate the testing data\n",
        "for i in range(n_iters+1,4902):\n",
        "  \n",
        "  category = new_categories1[keys[i]]\n",
        "  category_tensor = torch.tensor(category, dtype=torch.float)\n",
        "  line_tensor = lineToTensor(keys[i])\n",
        "  output = evaluate(line_tensor)\n",
        "  guess_new = categoryFromOutput(output)  \n",
        "\n",
        "  if guess_new == category:\n",
        "\n",
        "    correct =  '✓'\n",
        "    num_corr = num_corr + 1\n",
        "\n",
        "  else:\n",
        "\n",
        "    correct =  '✗ (%s)' % category \n",
        "\n",
        "  print('%d %d%% %s' % (i, i / n_iters * 100,correct))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iwUD-XuiazRR",
        "colab": {}
      },
      "source": [
        "#Here we are the printing the accuracy of the testing data \n",
        "print(num_corr/1000 * 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-wBLK-v1wXF",
        "colab_type": "text"
      },
      "source": [
        "#Training with GRU and Linear transformation layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1sSFO2d6rBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentimentNet2(nn.Module):\n",
        "    \"\"\"Here we build a custom class with GRU and Linear transformation layers\"\"\"\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
        "\n",
        "        super(SentimentNet2, self).__init__()\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True,bidirectional = True)\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "        \n",
        "    def forward(self, x, hidden,batch_size):\n",
        "\n",
        "        x = x.long()\n",
        "        embeds = self.embedding(x)\n",
        "        gru_out, hidden = self.gru(embeds, hidden)\n",
        "        gru_out = gru_out.contiguous().view(-1, self.hidden_dim)\n",
        "        out = self.dropout(gru_out)\n",
        "        out = self.fc(out)\n",
        "        out = self.softmax(out)\n",
        "        out = out.view(batch_size, -1)\n",
        "        out = out[:,-3:]\n",
        "\n",
        "        return out, hidden\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "      \n",
        "        weight = next(self.parameters()).data\n",
        "        hidden = weight.new(self.n_layers * 2, batch_size, self.hidden_dim).zero_().to(device)\n",
        "                   \n",
        "        return hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWpgnZONvKV_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Declaration of model object\n",
        "model2 = SentimentNet2(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "model2.to(device)\n",
        "lr=0.5\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adadelta(model2.parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcS6XECe6z4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def train2(category_tensors, line_tensors):\n",
        "  \"\"\"This function is used for training the model\"\"\"\n",
        "  final_loss = 0\n",
        "  correct_count = 0\n",
        "  for i in range(0,100):\n",
        "    line_tensor = line_tensors[i]\n",
        "    category = category_tensors[i] \n",
        "    category_tensor = torch.tensor(category, dtype=torch.float)\n",
        "    hidden = model2.init_hidden(batch_size)\n",
        "    \n",
        "    for j in range(line_tensor.size()[0]):\n",
        "        output,hidden = model2(line_tensor[j].to(device),hidden,batch_size)\n",
        "    guess_i = categoryFromOutput(output)\n",
        "    \n",
        "    if guess_i == category:\n",
        "      correct =  '✓'\n",
        "      correct_count = correct_count + 1\n",
        "    else:\n",
        "      correct =  '✗ (%s)' % category \n",
        "    loss = criterion(output.to(device), category_tensor.view(1,3).to(device))\n",
        "    final_loss = final_loss + loss\n",
        "\n",
        "  final_loss = final_loss/100\n",
        "\n",
        "  final_loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  return final_loss,correct_count  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI-FZxoaHydY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_iters = 3900\n",
        "print_every = 1\n",
        "cat_tensors = []\n",
        "line_tensors = []\n",
        "all_losses = []\n",
        "epochs = 3\n",
        "#We train the model in batches and print out the accuracy \n",
        "for epoch in range(epochs):\n",
        "\n",
        "  batch_num = 0\n",
        "  correct_sum = 0\n",
        "  final_loss = 0\n",
        "  model2.zero_grad()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  for iter in range(0,n_iters):\n",
        "    \n",
        "    while True:\n",
        "      \n",
        "      category = new_categories1[keys[iter]]\n",
        "      cat_tensors.append(category)\n",
        "      line_tensor = lineToTensor(keys[iter])\n",
        "      line_tensors.append(line_tensor)\n",
        "\n",
        "      if iter % 100 != 0 or iter == 0:\n",
        "\n",
        "        break\n",
        "\n",
        "      else:\n",
        "        batch_num = batch_num + 1\n",
        "        final_loss,correct = train2(cat_tensors,line_tensors)\n",
        "        correct_sum = correct_sum + correct\n",
        "        cat_tensors.clear()\n",
        "        line_tensors.clear()\n",
        "\n",
        "        if iter != 0:\n",
        "          \n",
        "          print('%d %d%% %.4f  %s %s' % (batch_num, correct_sum/ iter * 100, final_loss, correct_sum,epoch))\n",
        "          break\n",
        "\n",
        "  print( 'accuracy is %.6f%%' % (correct_sum/3900 * 100))   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFXCPFwDvKjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate2(line_tensor):\n",
        "    \"\"\"This function is used to evaluate the model\"\"\"\n",
        "    hidden = model2.init_hidden(batch_size)\n",
        "    for i in range(line_tensor.size()[0]):\n",
        "      output, hidden = model2(line_tensor[i].to(device), hidden,batch_size)\n",
        "       \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9-9cMszKzZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_corr2 = 0\n",
        "n_iters = 3900\n",
        "#Here we evaluate the testing data\n",
        "for i in range(n_iters+1,4902):\n",
        "  \n",
        "  category = new_categories1[keys[i]]\n",
        "  category_tensor = torch.tensor(category, dtype=torch.float)\n",
        "  line_tensor = lineToTensor(keys[i])\n",
        "  output = evaluate2(line_tensor)\n",
        "  guess_new = categoryFromOutput(output)  \n",
        "  if guess_new == category:\n",
        "    correct =  '✓'\n",
        "    num_corr2 = num_corr2+ 1\n",
        "  else:\n",
        "    correct =  '✗ (%s)' % category \n",
        "  print('%d %d%% %s' % (i, i / n_iters * 100,correct))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUlk42eHK9ri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Here we are the printing the accuracy of the testing data \n",
        "print(num_corr2/1000 * 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ys7H4tF3Thc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}